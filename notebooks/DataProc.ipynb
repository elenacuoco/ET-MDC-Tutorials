{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75b44c49-953b-4921-afd6-38f9fdf76f63",
   "metadata": {},
   "source": [
    "# Example of data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb286ae-5352-47a6-a6ea-07971dd7e7fd",
   "metadata": {},
   "source": [
    "### Time-Series Preprocessing and Power Spectral Density\n",
    "\n",
    "Time-series preprocessing is a crucial step in data analysis, particularly in fields like signal processing and data science. It involves several techniques aimed at enhancing the quality of the data, removing noise, and preparing it for further analysis. One essential aspect of time-series preprocessing is the calculation of the Power Spectral Density (PSD).\n",
    "\n",
    "#### What is Time-Series Preprocessing?\n",
    "\n",
    "- **Noise Removal**: Techniques such as filtering (e.g., low-pass, high-pass, band-pass) are used to remove unwanted noise from the signal.\n",
    "- **Detrending**: Removing trends from the data to focus on the underlying patterns or fluctuations.\n",
    "- **Normalization**: Scaling the data to a common range or distribution, often between 0 and 1, to facilitate comparisons between different datasets.\n",
    "- **Resampling**: Changing the sampling rate of the time series to match a desired frequency or to reduce computational complexity.\n",
    "- **Missing Data Handling**: Techniques for handling missing or incomplete data points, such as interpolation or imputation.\n",
    "\n",
    "#### Power Spectral Density (PSD)\n",
    "\n",
    "- **Definition**: The Power Spectral Density (PSD) is a measure of the power distribution of a signal as a function of frequency.\n",
    "- **Calculation**: It is calculated using techniques such as the Fast Fourier Transform (FFT) or the Welch method, which estimate the power spectrum of a signal from its time-domain representation.\n",
    "- **Interpretation**: PSD analysis helps in understanding the frequency components present in the signal and their relative strengths.\n",
    "- **Applications**: PSD is widely used for analyzing periodicities, identifying dominant frequencies, and characterizing noise properties.\n",
    "- **Normalization**: Often, PSD values are normalized to account for differences in signal power or to compare signals with different units or scales.\n",
    "\n",
    "#### Conclusion\n",
    "\n",
    "Time-series preprocessing, including techniques like noise removal and PSD calculation, is essential for extracting meaningful insights from data. These techniques help in uncovering underlying patterns, reducing noise interference, and preparing the data for further analysis or modeling.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85cf4a8-5a6b-4e74-a4b9-621eb0107198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the sys module to manipulate the Python runtime environment\n",
    "import sys\n",
    "\n",
    "# Adding a specific path to the beginning of the sys.path list\n",
    "# This path points to a directory containing Python packages\n",
    "# This is typically done to ensure that the desired version of a package is used\n",
    "# In this case, the path points to the site-packages directory of the igwn-py39 environment\n",
    "sys.path = ['/cvmfs/software.igwn.org/conda/envs/igwn-py39/lib/python3.9/site-packages'] + sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2219b34-fbfb-4037-94fc-a026ac76367c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the pyplot module from the matplotlib library and aliasing it as plt\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Importing the gwpy library, which provides tools for gravitational wave data analysis\n",
    "import gwpy\n",
    "\n",
    "# Importing the TimeSeries class from the gwpy.timeseries module\n",
    "from gwpy.timeseries import TimeSeries\n",
    "\n",
    "# Importing the NumPy library and aliasing it as np\n",
    "import numpy as np\n",
    "\n",
    "# Importing the Pandas library and aliasing it as pd\n",
    "import pandas as pd\n",
    "\n",
    "# Importing the seaborn library for statistical data visualization\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb16652-55b3-458e-a9f1-0fb4fa347707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the path to the directory containing the Einstein Telescope Mock Data Challenge 1 (MDC1) data\n",
    "MDC_PATH = \"/cvmfs/et-gw.osgstorage.org/et-gw/PUBLIC/MDC1/data\"\n",
    "\n",
    "# Defining a list of datasets, each identified by a string (E0, E1, ..., C2)\n",
    "DATASETS = ['E0','E1','E2','E3','C1','C2']\n",
    "\n",
    "# Creating a dictionary to map each dataset to its corresponding channel\n",
    "# Each channel is specified as a string with the dataset name followed by \":STRAIN\"\n",
    "CHANNELS = {n : f'{n}:STRAIN' for n in DATASETS}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37780321-1670-4e4c-9768-526df1e0d3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading a gravitational wave strain time series from a GWF file using the gwpy library\n",
    "# The file path is constructed based on the MDC_PATH and dataset ('E1') information\n",
    "e0 = TimeSeries.read(MDC_PATH+'/E1/E-E1_STRAIN_DATA-1000000000-2048.gwf', 'E1:STRAIN')\n",
    "\n",
    "# Printing the first 10 elements of the TimeSeries object (time series data)\n",
    "# The TimeSeries object contains various metadata and information about the strain data\n",
    "print(e0[1:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae73011e-021f-4023-a0ef-4a7966f7906e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enabling inline plotting in Jupyter notebooks or IPython environments\n",
    "%matplotlib inline\n",
    "\n",
    "# Creating a plot of the gravitational wave strain data using the plot() method of the TimeSeries object\n",
    "plot = e0.plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7419d644-3f96-446a-a815-2496f573da5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the amplitude spectral density (ASD) of the gravitational wave strain data\n",
    "# The ASD is calculated using a Fast Fourier Transform (FFT) with a specified length of 4 seconds\n",
    "# The median method is used to estimate the ASD\n",
    "asd = e0.asd(fftlength=4, method=\"median\")\n",
    "\n",
    "# Creating a plot of the computed ASD using the plot() method of the ASD object\n",
    "plot = asd.plot()\n",
    "\n",
    "# Displaying the plot while suppressing any warning messages (if any)\n",
    "plot.show(warn=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1038a20-386e-404f-bf8a-416848db2e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the current Axes instance from the plot\n",
    "ax = plot.gca()\n",
    "\n",
    "# Setting the x-axis (frequency) limits of the plot from 1 Hz to 4000 Hz\n",
    "ax.set_xlim(1, 4000)\n",
    "\n",
    "# Setting the y-axis (ASD values) limits of the plot from 1e-25 to 1e-23\n",
    "ax.set_ylim(1e-25, 1e-23)\n",
    "\n",
    "# Displaying the updated plot with adjusted axis limits\n",
    "plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1557e128-5eec-458a-9fc5-ac0d3042a19f",
   "metadata": {},
   "source": [
    "## Whitening"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aebc91fc-e1e5-4b81-8a8b-39a376d05854",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Whitening Procedure in Data Analysis\n",
    "\n",
    "Whitening is a data preprocessing technique used to remove correlations between variables and normalize the variance of each feature. \n",
    "It is particularly useful in signal processing, machine learning, and statistics to improve the performance of algorithms and facilitate the interpretation of results.\n",
    "The purpose of whitening is to modify the data such that the noise is spectrally flat, meaning it has an equal amount of power across all frequencies. This is done by applying a filter that compensates for the frequency-dependent response of the detector. The whitening process significantly improves the sensitivity of the detectors, enabling scientists to extract \n",
    "weak signals from the noise and identify potential gravitational wave events. Whitening can be done using techniques in frequency domain or in time-domain.\n",
    "\n",
    "#### How Whitening Works\n",
    "\n",
    "- **Decorrelation**: The primary objective of whitening is to decorrelate the features of the dataset. This is achieved by transforming the data such that the covariance matrix becomes the identity matrix. In other words, the transformed features are uncorrelated.\n",
    "- **Normalization**: Whitening also involves normalizing the variance of each feature to be equal to one. This ensures that all features have the same scale and prevents features with larger variances from dominating the analysis.\n",
    "- **Mathematical Transformation**: The whitening transformation is typically performed using techniques like Principal Component Analysis (PCA) or ZCA (Zero-phase Component Analysis). PCA whitening involves rotating the data to align with its principal components, while ZCA whitening additionally scales the data to account for the variances.\n",
    "- **Centering**: Before applying whitening, it's essential to center the data by subtracting the mean of each feature. This ensures that the transformation is applied around the origin of the feature space.\n",
    "\n",
    "#### Applications of Whitening\n",
    "\n",
    "- **Feature Engineering**: Whitening can improve the performance of machine learning algorithms by removing redundant information and reducing the impact of noise.\n",
    "- **Data Visualization**: Whitening can facilitate data visualization by simplifying the structure of the data and making it easier to identify patterns and relationships.\n",
    "- **Signal Processing**: In signal processing, whitening can be used to preprocess signals before further analysis, such as in the detection of signals in noise or in source localization problems.\n",
    "- **Statistical Analysis**: Whitening is also useful in statistical analysis to ensure that variables are independent and identically distributed, which can improve the validity of statistical tests and models.\n",
    "\n",
    "#### Considerations and Limitations\n",
    "\n",
    "- **Computational Cost**: Whitening procedures may be computationally expensive, especially for large datasets, due to the need for matrix operations and eigenvalue decompositions.\n",
    "- **Sensitivity to Outliers**: Whitening techniques can be sensitive to outliers in the data, which may affect the estimation of covariance matrices and lead to suboptimal results.\n",
    "- **Dimensionality Reduction**: Whitening can implicitly perform dimensionality reduction by reducing the dimensionality of the feature space to the number of uncorrelated features. However, this reduction may not always capture all the relevant information in the data.\n",
    "\n",
    "### Whitening in frequency domain\n",
    "The whitening process involves several steps. First, the data is transformed into the frequency domain using techniques such as fast Fourier transforms (FFT). Then, the noise spectrum is estimated by analyzing the power spectral density of the data. This spectrum represents the distribution of noise power across different frequencies.\n",
    "Next, an inverse filter is applied to the data, which modifies the spectrum of the signal to flatten the noise. Essentially, the inverse filter boosts or attenuates specific frequency components to compensate for the frequency-dependent response of the detector. This equalization allows gravitational wave signals to be more easily distinguished from the noise. After the whitening procedure, the data is transformed back into the time domain, where it undergoes further analysis and searches for gravitational wave signals using sophisticated algorithms.\n",
    "\n",
    "\n",
    "\n",
    "### GW data before and after the whitening\n",
    "In the following tutorial we will use the FFT whitening used in the GW community, contained in gwpy package. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b40b66-7b70-43a7-8bc7-2b447136dbc4",
   "metadata": {},
   "source": [
    "## Whiten the data, using gwpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f91ad1-c7bb-4677-aed4-8cf80cfb0a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whitening the strain data using a window of 4 seconds and a step of 2 seconds\n",
    "white = e0.whiten(16, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7f2f8f-b9a5-49f3-85a3-970dbc5e63a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating and displaying a multi-panel plot\n",
    "\n",
    "# Import the 'Plot' class from the 'gwpy.plot' module\n",
    "from gwpy.plot import Plot\n",
    "\n",
    "# Create a multi-panel plot ('plot') with two panels: one for 'strain' data and one for 'white' data\n",
    "# The 'separate=True' argument creates separate y-axes for each panel\n",
    "# The 'sharex=True' argument shares the x-axis between the panels\n",
    "plot = Plot(e0, white, separate=True, sharex=True)\n",
    "\n",
    "# Set the y-axis label for the first panel (strain data)\n",
    "plot.axes[0].set_ylabel('Y-arm power [counts]', fontsize=16)\n",
    "\n",
    "# Set the y-axis label for the second panel (whitened data)\n",
    "plot.axes[1].set_ylabel('Whitened amplitude', fontsize=16)\n",
    "\n",
    "# Display the multi-panel plot\n",
    "plot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05291dc7-f9ac-42a6-bf8c-c8253a9f44db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Amplitude Spectral Density (ASD)\n",
    "\n",
    "# Calculate and plot the ASD (Amplitude Spectral Density) of the original 'strain' data\n",
    "# The 'fftlength=4' argument sets the length of the Fast Fourier Transform (FFT) window to 4 seconds\n",
    "fig1 = e0.asd(fftlength=4).plot()\n",
    "\n",
    "# Calculate and plot the ASD of the whitened 'white' data\n",
    "# The 'fftlength=4' argument sets the length of the FFT window to 4 seconds\n",
    "fig2 = white.asd(fftlength=4).plot()\n",
    "\n",
    "# Uncomment the following lines to set custom x-axis and y-axis limits:\n",
    "# plt.xlim(10, 2000)   # Set custom x-axis limits (frequency range)\n",
    "# plt.ylim(1e-24, 1e-19)   # Set custom y-axis limits (ASD values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3d44ae-70f2-493e-90ee-6a6251d6e946",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Whitening in time domain\n",
    "The parametric estimator for whitening in the time domain involves selecting a noise model, estimating its parameters from the data, and subtracting or filtering out the estimated noise component. In the time domain, a parametric estimator assumes a specific mathematical model or functional form for the noise. This model is typically characterized by a set of parameters that are estimated from the data. By fitting the model to the data, the parameters are determined, and the noise can be whitened by removing the estimated noise component. To apply a parametric estimator for whitening in the time domain, the first step is to select an appropriate model for the noise. Common choices include autoregressive (AR) models, autoregressive moving average (ARMA) models. These models capture different properties of the noise, such as its autocorrelation and spectral characteristics. Once the model is selected, the parameters of the model are estimated from the data. This estimation is typically done using methods such as maximum likelihood estimation (MLE) or least squares fitting. The estimated parameters describe the noise component that needs to be removed or filtered from the data. After estimating the parameters, the parametric estimator is applied to the data. The estimated noise component is subtracted or filtered out from the original data, leaving behind a whitened version of the data. This whitened data has reduced noise correlations and a more constant power spectral density, which enhances the detectability of gravitational wave signals. It's important to note that the effectiveness of the parametric estimator depends on the accuracy of the chosen noise model and the quality of the parameter estimation. If the model is a good fit for the noise characteristics and the parameter estimation is reliable, the whitening procedure can significantly improve the sensitivity of gravitational wave analysis. However, it's worth mentioning that the choice of parametric models and their applicability to gravitational wave search can be challenging. The noise in gravitational wave detectors often exhibits complex and non-stationary behavior, which may require more sophisticated modeling approaches or combinations of different models. While less commonly used compared to the frequency domain non-parametric methods, the parametric approach can be valuable in specific scenarios where the noise characteristics are well-modeled by the chosen parametric model. It provides an alternative approach to whitening in gravitational wave search, aiming to enhance the detectability of gravitational wave signals by reducing noise correlations and improving the data quality.\n",
    "If you are interested also in time domain solution, you can have a look at these packages:\n",
    "\n",
    "* https://github.com/elenacuoco/p4TSA\n",
    "\n",
    "* https://wdfpipe.gitlab.io/ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc5affd-ee1f-4b77-8017-5c5b5939a171",
   "metadata": {},
   "source": [
    "## Implement the whitening using AR model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff2c081-cc77-45c5-8595-1b65297dce13",
   "metadata": {},
   "source": [
    "### Create AR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bc58a1-cccf-4e6e-8321-ec677b6bd0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import json \n",
    "from pytsa.tsa import SeqView_double_t as SV\n",
    "from wdf.config.Parameters import Parameters\n",
    "from wdf.processes.Whitening import Whitening\n",
    "from wdf.processes.DWhitening import  DWhitening\n",
    "from pytsa.tsa import FrameIChannel\n",
    "import logging, sys\n",
    "\n",
    "# Configure logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Set up logging output\n",
    "console_handler = logging.StreamHandler(sys.stdout)\n",
    "logger.addHandler(console_handler)\n",
    "\n",
    "# Log a debug message\n",
    "logging.debug(\"info\")\n",
    "\n",
    "# Define input file path\n",
    "filein = MDC_PATH + '/E1/E-E1_STRAIN_DATA-1000000000-2048.gwf'\n",
    "\n",
    "# Flag to determine whether to create a new JSON configuration file\n",
    "new_json_config_file = True\n",
    "\n",
    "# Create or update JSON configuration file if needed\n",
    "if new_json_config_file:\n",
    "    configuration = {\n",
    "      \"file\": filein,\n",
    "      \"channel\": 'E1:STRAIN', \n",
    "      \"len\": 1.0,\n",
    "      \"gps\": 1000000000.0001221,\n",
    "      \"outdir\": \"./\",\n",
    "      \"dir\": \"./\", \n",
    "      \"ARorder\": 1000,\n",
    "      \"learn\": 200,\n",
    "      \"preWhite\": 4\n",
    "    }\n",
    "\n",
    "    filejson = os.path.join(os.getcwd(), \"parameters.json\")\n",
    "    with open(filejson, \"w+\") as file_json:\n",
    "        json.dump(configuration, file_json)\n",
    "\n",
    "# Log message indicating parameters are read from JSON file\n",
    "logging.info(\"read parameters from JSON file\")\n",
    "\n",
    "# Load parameters from JSON file\n",
    "par = Parameters()\n",
    "filejson = \"parameters.json\"\n",
    "try:\n",
    "    par.load(filejson)\n",
    "except IOError:\n",
    "    logging.error(\"Cannot find resource file \" + filejson)\n",
    "    quit()\n",
    "\n",
    "# Initialize FrameIChannel object\n",
    "strInfo = FrameIChannel(par.file, par.channel, 1.0, par.gps)\n",
    "Info = SV()\n",
    "strInfo.GetData(Info)\n",
    "par.sampling = int(1.0 / Info.GetSampling())\n",
    "\n",
    "# Log channel information\n",
    "logging.info(\"channel = %s at sampling frequency = %s\" % (par.channel, par.sampling))\n",
    "\n",
    "# Initialize Whitening object\n",
    "whiten = Whitening(par.ARorder)  \n",
    "\n",
    "# Set paths for AR and LV coefficient files\n",
    "par.ARfile = \"./ARcoeff-AR%s-fs%s-%s.txt\" % (par.ARorder, par.sampling, par.channel)\n",
    "par.LVfile = \"./LVcoeff-AR%s-fs%s-%s.txt\" % (par.ARorder, par.sampling, par.channel)\n",
    "\n",
    "# Load AR parameters if files exist, otherwise estimate and save AR parameters\n",
    "if os.path.isfile(par.ARfile) and os.path.isfile(par.LVfile):\n",
    "    logging.info('Load AR parameters')\n",
    "    whiten.ParametersLoad(par.ARfile, par.LVfile)\n",
    "else:\n",
    "    logging.info('Start AR parameter estimation')\n",
    "    \n",
    "    # Read data for AR estimation\n",
    "    strLearn = FrameIChannel(par.file, par.channel, par.learn, par.gps)\n",
    "    Learn = SV()\n",
    "    strLearn.GetData(Learn)   \n",
    "    \n",
    "    # Estimate AR parameters\n",
    "    whiten.ParametersEstimate(Learn)\n",
    "    \n",
    "    # Save AR parameters\n",
    "    whiten.ParametersSave(par.ARfile, par.LVfile)\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b86df366-59d7-4ab2-882f-e1fca5263c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sigma for the noise\n",
    "par.sigma = whiten.GetSigma()\n",
    "logging.info('Estimated sigma= %s' % par.sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47a29c1-f25b-4079-8deb-2fd07d7ff9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize the loop for the whitening and double whitening\n",
    "data = SV()\n",
    "dataw = SV()\n",
    "dataww =SV()\n",
    " \n",
    "streaming = FrameIChannel(par.file, par.channel, par.len, par.gps)\n",
    "streaming.GetData(data)\n",
    "N=data.GetSize()\n",
    "   \n",
    "Dwhiten=DWhitening(whiten.LV,N,0)\n",
    "if os.path.isfile(par.LVfile):\n",
    "    logging.info('Load LV parameters')\n",
    "    Dwhiten.ParametersLoad(par.LVfile)\n",
    "###---whitening preheating---###\n",
    "for i in range(par.preWhite):\n",
    "    streaming.GetData(data)\n",
    "    whiten.Process(data, dataw)\n",
    "    Dwhiten.Process(data, dataww)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa30618-2855-4639-992e-3b85b3a534b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data to be plotted \n",
    "streaming.GetData(data)\n",
    "whiten.Process(data, dataw)\n",
    "Dwhiten.Process(data, dataww)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96cfe3a3-7768-494c-9697-0979a1d149c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "# Suppress warnings from matplotlib\n",
    "mpl_logger = logging.getLogger(\"matplotlib\")\n",
    "mpl_logger.setLevel(logging.WARNING)\n",
    "\n",
    "# Enable inline plotting\n",
    "%matplotlib inline\n",
    "\n",
    "# Set default figure size\n",
    "plt.rcParams['figure.figsize'] = (15.0, 10.0)\n",
    "\n",
    "# Initialize arrays for data\n",
    "x = np.zeros(data.GetSize())\n",
    "y = np.zeros(data.GetSize())\n",
    "yw = np.zeros(data.GetSize())\n",
    "yww = np.zeros(data.GetSize())\n",
    "\n",
    "# Extract data points\n",
    "for i in range(data.GetSize()):\n",
    "    x[i] = data.GetX(i)\n",
    "    y[i] = data.GetY(0, i)\n",
    "    yw[i] = dataw.GetY(0, i)\n",
    "    yww[i] = dataww.GetY(0, i)\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(x, y, label='Raw data')\n",
    "plt.plot(x, yw, label='Whitened data')\n",
    "plt.plot(x, yww, label='Double whitened data')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231967c0-f5ab-4dee-b130-cc75f8cb7e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Calculate power spectral density (PSD) using Welch's method\n",
    "f, Pxx_den = signal.welch(y, par.sampling, nperseg=2048)\n",
    "f, Pxx_denW = signal.welch(yw, par.sampling, nperseg=2048)\n",
    "f, Pxx_denWW = signal.welch(yww, par.sampling, nperseg=2048)\n",
    "\n",
    "# Create a new figure and axis object\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot PSD for raw data\n",
    "ax.semilogy(f, Pxx_den, label='Raw data')\n",
    "\n",
    "# Plot PSD for whitened data\n",
    "ax.semilogy(f, Pxx_denW, label='Whitened data')\n",
    "\n",
    "# Plot PSD for double whitened data\n",
    "ax.semilogy(f, Pxx_denWW, label='Double whitened data')\n",
    "\n",
    "# Set labels for x and y axes\n",
    "plt.xlabel('frequency [Hz]')\n",
    "plt.ylabel('PSD [V**2/Hz]')\n",
    "\n",
    "# Add legend\n",
    "plt.legend()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6e92271-0539-47b0-aa21-0780132b4b1f",
   "metadata": {},
   "source": [
    "## <span style=\"color:purple\">Challenge: what change if you use a different number of AR model? Explain why.</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed94305-40ea-4736-8227-2585e9e1a445",
   "metadata": {},
   "source": [
    "## Let' have a look at the Time-frequency plot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ed903b-1a1e-42fa-9856-c92bd3552693",
   "metadata": {},
   "source": [
    "### Time-Frequency Transform in Signal Processing\n",
    "\n",
    "Time-frequency transform is a powerful technique in signal processing that provides a detailed analysis of how the frequency content of a signal changes over time. Unlike traditional Fourier analysis, which provides a static representation of frequency content, time-frequency transforms offer insights into the dynamic nature of signals, making them particularly useful for analyzing non-stationary signals.\n",
    "\n",
    "#### Fourier Transform vs. Time-Frequency Transform\n",
    "\n",
    "- **Fourier Transform**: Fourier analysis decomposes a signal into its frequency components, providing information about the amplitude and phase of each frequency present in the signal. However, it does not capture how the frequency content evolves over time, making it less suitable for analyzing non-stationary signals.\n",
    "\n",
    "- **Time-Frequency Transform**: Time-frequency transforms, such as the Short-Time Fourier Transform (STFT), Wavelet Transform, and Wigner-Ville Distribution, overcome this limitation by providing a time-varying representation of frequency content. They divide the signal into short segments and analyze the frequency content of each segment separately, allowing for the detection of transient events and frequency modulations.\n",
    "\n",
    "#### Types of Time-Frequency Transforms\n",
    "\n",
    "1. **Short-Time Fourier Transform (STFT)**: STFT computes the Fourier transform of short segments of a signal, providing a time-varying representation of frequency content. It is widely used for tasks such as audio processing, speech recognition, and vibration analysis.\n",
    "\n",
    "2. **Wavelet Transform**: Wavelet transform decomposes a signal into wavelet coefficients at different scales and positions. It offers excellent time and frequency localization, making it suitable for analyzing signals with varying frequency components.\n",
    " \n",
    " \n",
    "\n",
    "Overall, time-frequency transforms play a crucial role in analyzing non-stationary signals across various domains, providing valuable insights into the dynamic behavior of signals over time and frequency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a30848-c7fa-4e3c-8fba-cbd56fcbdaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries and modules\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython\n",
    "import IPython.display\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm\n",
    "from scipy import signal\n",
    "from matplotlib.colors import LogNorm\n",
    "from PIL import Image\n",
    "\n",
    "# Set matplotlib configuration parameters\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "\n",
    "# Import NumPy library\n",
    "import numpy as np\n",
    "\n",
    "# Import additional libraries and modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import signal\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "def prepareImage(y, fs, title):\n",
    "    \"\"\"\n",
    "    Create and display a spectrogram plot using the Short-Time Fourier Transform (STFT).\n",
    "\n",
    "    Parameters:\n",
    "        y (numpy.ndarray): Signal data.\n",
    "        fs (float): Sampling frequency.\n",
    "        title (str): Title for the plot.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Calculate the spectrogram using the Short-Time Fourier Transform (STFT)\n",
    "    f, t, Sxx = signal.spectrogram(y, fs)\n",
    "    \n",
    "    # Create a pseudocolor mesh plot using the spectrogram data\n",
    "    plt.pcolormesh(t, f, Sxx, cmap='viridis', shading='gouraud', alpha=0.95)\n",
    "    \n",
    "    # Set the y-axis scale to logarithmic\n",
    "    plt.yscale('log')\n",
    "    \n",
    "    # Set the y-axis limits to be between 10 Hz and half of the sampling frequency\n",
    "    plt.ylim(10, fs/2)\n",
    "    \n",
    "    # Set the title for the plot\n",
    "    plt.title(str(title))\n",
    "    \n",
    "    # Set labels for the x and y axes\n",
    "    plt.xlabel('Time (secs)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    \n",
    "    # Add a colorbar to the plot for visualization\n",
    "    plt.colorbar()\n",
    "    \n",
    "    # Display the spectrogram plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965863df-390f-42f9-90b3-fa1baa2330c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs=8192\n",
    "prepareImage(yw,fs,title=\"Spectrogram\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1893747a-8214-413b-84f1-ad317745f403",
   "metadata": {},
   "source": [
    "## Let's whiten the data containing a high-SNR signal and plot it for not whitened and whitened data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
